{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLC9TWvmDUdz",
        "outputId": "8f8d6fe2-8425-4245-ea66-4d6a4b0bddeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community[all]\n",
            "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
            "\u001b[33mWARNING: langchain-community 0.3.18 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain-core<1.0.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (0.3.37)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (0.3.19)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community[all])\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community[all])\n",
            "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (0.3.8)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community[all])\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community[all]) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community[all]) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community[all])\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community[all])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community[all]) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.19->langchain_community[all]) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community[all]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community[all]) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.37->langchain_community[all]) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community[all]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community[all]) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community[all]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community[all]) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community[all])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community[all]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community[all]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community[all]) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community[all]) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community[all]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community[all]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community[all]) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.37->langchain_community[all]) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.19->langchain_community[all]) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community[all])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community[all]) (1.3.1)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.18 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Collecting llama-parse\n",
            "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting llama-cloud-services>=0.6.1 (from llama-parse)\n",
            "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.1->llama-parse) (8.1.8)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.11 (from llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading llama_cloud-0.1.13-py3-none-any.whl.metadata (800 bytes)\n",
            "Collecting llama-index-core>=0.11.0 (from llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading llama_index_core-0.12.19-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pydantic!=2.10 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.1->llama-parse) (2.10.6)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.1->llama-parse) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (2025.1.31)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (0.28.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.11.12)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (9.0.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.17.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.1->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.10->llama-cloud-services>=0.6.1->llama-parse) (2.27.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (0.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-cloud-services>=0.6.1->llama-parse) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->llama-cloud<0.2.0,>=0.1.11->llama-cloud-services>=0.6.1->llama-parse) (1.3.1)\n",
            "Downloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
            "Downloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
            "Downloading llama_cloud-0.1.13-py3-none-any.whl (253 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.4/253.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_core-0.12.19-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, dirtyjson, tiktoken, llama-index-core, llama-cloud, llama-cloud-services, llama-parse\n",
            "Successfully installed dirtyjson-1.0.8 filetype-1.2.0 llama-cloud-0.1.13 llama-cloud-services-0.6.1 llama-index-core-0.12.19 llama-parse-0.6.1 tiktoken-0.9.0\n",
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.13.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (1.70.0)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant_client)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.10.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.3.0)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant_client)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools>=1.41.0->qdrant_client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->qdrant_client) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.8->qdrant_client) (4.12.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Downloading qdrant_client-1.13.2-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, portalocker, grpcio-tools, qdrant_client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "Successfully installed grpcio-tools-1.70.0 portalocker-2.10.1 protobuf-5.29.3 qdrant_client-1.13.2\n",
            "Collecting langchain_qdrant\n",
            "  Downloading langchain_qdrant-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langchain_qdrant) (0.3.37)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain_qdrant) (2.10.6)\n",
            "Requirement already satisfied: qdrant-client<2.0.0,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain_qdrant) (1.13.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (0.3.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_qdrant) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_qdrant) (2.27.2)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (1.70.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (1.70.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (1.26.4)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (2.3.0)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.11/dist-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (5.29.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (4.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (0.23.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (4.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain_qdrant) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain_qdrant) (1.3.1)\n",
            "Downloading langchain_qdrant-0.2.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: langchain_qdrant\n",
            "Successfully installed langchain_qdrant-0.2.0\n",
            "Collecting ollama\n",
            "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.10.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
            "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community[all]\n",
        "!pip install llama-parse\n",
        "!pip install qdrant_client\n",
        "!pip install langchain_qdrant\n",
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vctuWs9yIdCI"
      },
      "source": [
        "Import Library\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZlIku1tcCy6z"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS-3070\\Desktop\\Github\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import uuid\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader, UnstructuredMarkdownLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "from langchain_qdrant import FastEmbedSparse, Qdrant\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_core.documents import Document\n",
        "import nest_asyncio\n",
        "from llama_parse import LlamaParse\n",
        "import ollama\n",
        "from langchain_community.embeddings import OllamaEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GbJPPLitXk5J"
      },
      "outputs": [],
      "source": [
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5JM78hSIgvF"
      },
      "source": [
        "API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz8ly7yuFIZu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J4GgFjzHcWZ"
      },
      "outputs": [],
      "source": [
        "qdrant_url = os.environ[\"QDRANT_URL\"]\n",
        "qdrant_api_key = os.environ[\"QDRANT_API_KEY\"]\n",
        "collection_name = \"Ollama-RAG\"\n",
        "\n",
        "qdrant_client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IheYOyZtJewQ",
        "outputId": "77135bd3-2857-4813-93c2-f2037d2f137d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\3637584716.py:2: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  vectorstore = Qdrant(\n",
            "c:\\Users\\ASUS-3070\\Desktop\\Github\\.venv\\lib\\site-packages\\langchain_community\\vectorstores\\qdrant.py:152: UserWarning: `embeddings` should be an instance of `Embeddings`.Using `embeddings` as `embedding_function` which is deprecated\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# --- Vectorstore Initialization (Langchain Qdrant) ---\n",
        "vectorstore = Qdrant(\n",
        "    client=qdrant_client,\n",
        "    collection_name=collection_name,\n",
        "    embeddings=OllamaEmbeddings,  # We're handling embeddings separately\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPtg0VBXIi0i"
      },
      "source": [
        "Loading and Embedded Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D4sBlkXrHr2v"
      },
      "outputs": [],
      "source": [
        "def load_and_embed_documents(file_path):\n",
        "    def load_document(file_path):\n",
        "        if file_path.endswith(\".pdf\"):\n",
        "            loader = PyPDFLoader(file_path)\n",
        "        elif file_path.endswith(\".txt\"):\n",
        "            loader = TextLoader(file_path)\n",
        "        elif file_path.endswith(\".md\"):\n",
        "            loader = UnstructuredMarkdownLoader(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type: {file_path}\")\n",
        "        documents = loader.load()\n",
        "        return documents\n",
        "\n",
        "    def create_chunks(documents):\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        return chunks\n",
        "\n",
        "    documents = load_document(file_path)\n",
        "    chunks = create_chunks(documents)\n",
        "\n",
        "    # Embeddings setup:\n",
        "    sparse_embeddings_engine = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
        "\n",
        "    for chunk in chunks:\n",
        "        text = chunk.page_content\n",
        "        dense_embedding = ollama.embeddings(model='mxbai-embed-large', prompt=text)['embedding']\n",
        "        sparse_embedding = sparse_embeddings_engine.embed_query(text)\n",
        "\n",
        "        # Create a Langchain Document object with dense and sparse vectors\n",
        "        doc = Document(\n",
        "            page_content=text,\n",
        "            metadata=chunk.metadata,\n",
        "            embedding={\"dense\": dense_embedding, \"sparse\": sparse_embedding}\n",
        "        )\n",
        "\n",
        "        # Add the document to the Langchain vectorstore\n",
        "        vectorstore.add_documents([doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zl6Nbn1IrF9"
      },
      "source": [
        "Hybrid Search Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o8Lk4Yj6IRz_"
      },
      "outputs": [],
      "source": [
        "def hybrid_search(query: str, collection: str, limit: int = 5):\n",
        "    dense_vector = ollama.embeddings(model='rjmalagon/gte-qwen2-1.5b-instruct-embed-f16', prompt=query)\n",
        "\n",
        "    results = qdrant_client.search(\n",
        "            collection_name=collection_name,\n",
        "            query_vector=models.NamedVector(\n",
        "                name=\"gte-qwen1.5\",\n",
        "                vector=dense_vector['embedding']\n",
        "            ),\n",
        "            limit=limit,\n",
        "            search_params=models.SearchParams(\n",
        "                hnsw_ef=128\n",
        "            )\n",
        "    )\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\185713141.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = qdrant_client.search(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[ScoredPoint(id=8, version=0, score=0.62523055, payload={'text': '1 Introduction\\n1.1 What is Machine Learning\\nMachine learning is a subﬁeld of computer science that is concerned with building algorithms\\nwhich, to be useful, rely on a collection of examples of some phenomenon. These examples\\ncan come from nature, be handcrafted by humans or generated by another algorithm.\\nMachine learning can also be deﬁned as the process of solving a practical problem by 1)\\ngathering a dataset, and 2) algorithmically building a statistical model based on that dataset.', 'metadata': {'source': 'C:/Users/shaoe/OneDrive/Desktop/AAI3008LLM/The_Hundred_page_Machine_Learning_Book_Andriy_Burkov_Z_Library.pdf', 'page': 2}}, vector=None, shard_key=None, order_value=None),\n",
              " ScoredPoint(id=4, version=0, score=0.5865381, payload={'text': 'As you can see, just like artiﬁcial intelligence is not intelligence, machine learning is not\\nlearning. However, machine learning is a universally recognized term that usually refers\\nto the science and engineering of building machines capable of doing various useful things\\nwithout being explicitly programmed to do so. So, the word “learning” in the term is used\\nby analogy with the learning in animals rather than literally.\\nWho This Book is For', 'metadata': {'source': 'C:/Users/shaoe/OneDrive/Desktop/AAI3008LLM/The_Hundred_page_Machine_Learning_Book_Andriy_Burkov_Z_Library.pdf', 'page': 1}}, vector=None, shard_key=None, order_value=None),\n",
              " ScoredPoint(id=1, version=0, score=0.54910356, payload={'text': 'Preface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs for most other inputs (distinct from the training data) on the condition that\\nthose inputs come from the same or a similar statistical distribution as the one the training\\ndata was drawn from.', 'metadata': {'source': 'C:/Users/shaoe/OneDrive/Desktop/AAI3008LLM/The_Hundred_page_Machine_Learning_Book_Andriy_Burkov_Z_Library.pdf', 'page': 1}}, vector=None, shard_key=None, order_value=None),\n",
              " ScoredPoint(id=3, version=0, score=0.529855, payload={'text': 'game on a rotated screen.\\nSo why the name “machine learning” then? The reason, as is often the case, is marketing:\\nArthur Samuel, an American pioneer in the ﬁeld of computer gaming and artiﬁcial intelligence,\\ncoined the term in 1959 while at IBM. Similarly to how in the 2010s IBM tried to market\\nthe term “cognitive computing” to stand out from competition, in the 1960s, IBM used the\\nnew cool term “machine learning” to attract both clients and talented employees.', 'metadata': {'source': 'C:/Users/shaoe/OneDrive/Desktop/AAI3008LLM/The_Hundred_page_Machine_Learning_Book_Andriy_Burkov_Z_Library.pdf', 'page': 1}}, vector=None, shard_key=None, order_value=None),\n",
              " ScoredPoint(id=235, version=23, score=0.52809525, payload={'text': 'Figure 1: Machine learning algorithm selection diagram for scikit-learn.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10', 'metadata': {'source': 'C:/Users/shaoe/OneDrive/Desktop/AAI3008LLM/The_Hundred_page_Machine_Learning_Book_Andriy_Burkov_Z_Library.pdf', 'page': 50}}, vector=None, shard_key=None, order_value=None)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hybrid_search(\"What is machine learning?\", \"Ollama-RAG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\185713141.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = qdrant_client.search(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Database Context: 1 Introduction\\n1.1 What is Machine Learning\\nMachine learning is a subﬁeld of computer science that is concerned with building algorithms\\nwhich, to be useful, rely on a collection of examples of some phenomenon. These examples\\ncan come from nature, be handcrafted by humans or generated by another algorithm.\\nMachine learning can also be deﬁned as the process of solving a practical problem by 1)\\ngathering a dataset, and 2) algorithmically building a statistical model based on that dataset.As you can see, just like artiﬁcial intelligence is not intelligence, machine learning is not\\nlearning. However, machine learning is a universally recognized term that usually refers\\nto the science and engineering of building machines capable of doing various useful things\\nwithout being explicitly programmed to do so. So, the word “learning” in the term is used\\nby analogy with the learning in animals rather than literally.\\nWho This Book is ForPreface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs for most other inputs (distinct from the training data) on the condition that\\nthose inputs come from the same or a similar statistical distribution as the one the training\\ndata was drawn from.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def retrieve_documents(query):\n",
        "    results = hybrid_search(query, collection=collection_name, limit=3)  # Use hybrid search here\n",
        "    list = \"Database Context: \"\n",
        "    for i in range(len(results)):\n",
        "        list += str(results[i].payload['text'])\n",
        "    return list\n",
        "\n",
        "retrieve_documents(\"What is machine learning?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldaXDaYxIu24"
      },
      "source": [
        "RAG Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1tgu9WEHIyuk"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.utilities import GoogleSearchAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7cudGe4-I0un"
      },
      "outputs": [],
      "source": [
        "def get_rag_chain(enable_search=False):\n",
        "    \"\"\"Creates and returns the RAG chain with hybrid search and optional Google Search.\"\"\"\n",
        "\n",
        "    # Initialize the LLM\n",
        "    llm = Ollama(model=\"phi3:mini\")\n",
        "\n",
        "    # Create a prompt template\n",
        "    template = \"\"\"Answer the question based on the following context:\n",
        "    {context}\n",
        "    {online_context}\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "    # Function to retrieve relevant documents using hybrid search\n",
        "    def retrieve_documents(query):\n",
        "        results = hybrid_search(query, collection=collection_name, limit=3)  # Upgrade to hybrid search here\n",
        "        list = \"Database Context: \"\n",
        "        for i in range(len(results)):\n",
        "            list += str(results[i].payload['text'])\n",
        "        #print(f\"{list}\") # This one maybe fix to add metadata content\n",
        "        return list \n",
        "\n",
        "    # Add online searching, defaulting to empty string if search is disabled\n",
        "    def online_search(query):\n",
        "        \"\"\"Searches Google and returns a summary of the results.\"\"\"\n",
        "        search = GoogleSearchAPIWrapper()\n",
        "        search_results = search.run(query)\n",
        "        if not search_results:\n",
        "            search_results = \"No relevant information found online.\"  # Handle empty results\n",
        "        #print(f\"Online Search Results: {search_results}\")  # Debugging\n",
        "        return f\"Online search results: {search_results}\"\n",
        "    \n",
        "    def filler(query):\n",
        "        #print(\"Online Search Switched off\")\n",
        "        return f\"Online Search Switched Off\"\n",
        "    \n",
        "    if enable_search:\n",
        "        rag_chain = (\n",
        "        {\"context\": retrieve_documents, ### This need \n",
        "         \"question\": RunnablePassthrough(),\n",
        "         \"online_context\": online_search} ### This is correct\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    else:\n",
        "        rag_chain = (\n",
        "        {\"context\": retrieve_documents, ### This need \n",
        "         \"question\": RunnablePassthrough(),\n",
        "         \"online_context\": filler} ### This is correct\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return rag_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YvTe_rEJIme"
      },
      "source": [
        "Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VAjB1o7EI8H_"
      },
      "outputs": [],
      "source": [
        "def agent_search(query):\n",
        "    \"\"\"Search for relevant information in the document and online.\"\"\"\n",
        "    rag_chain = get_rag_chain(enable_search=False)  # Enable online search\n",
        "    response = rag_chain.invoke(query)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OrvhO4iQKkrM"
      },
      "outputs": [],
      "source": [
        "def load_user_document(file_path):\n",
        "    \"\"\"Loads a user-provided document and adds it to the vectorstore.\"\"\"\n",
        "    try:\n",
        "        load_and_embed_documents(file_path)\n",
        "        return \"Document loaded and processed successfully.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error loading document: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F4k3wPeeqONN"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cFQnqC4zqR9R"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name=\"document_search\",\n",
        "        func=agent_search,\n",
        "        description=\"useful for when you need to answer questions about the document and online.\"\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2zw9Rq46qay_"
      },
      "outputs": [],
      "source": [
        "# --- Agent Initialization ---\n",
        "from langchain_community.llms import Ollama\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUPqDdeJqb2H",
        "outputId": "f78ce230-4d35-45c9-eeb8-fc4ba5a6dd25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\1301706811.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
            "  llm = Ollama(model=\"phi3:mini\")\n",
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\1301706811.py:2: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
          ]
        }
      ],
      "source": [
        "llm = Ollama(model=\"phi3:mini\")\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vFRIuoVwdn3Y"
      },
      "outputs": [],
      "source": [
        "from langchain_google_community import GoogleSearchAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "0w-aff7iqhWB",
        "outputId": "82c8a1ec-e62a-4b65-944e-463e7ae01e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mQuestion: What is machine learning?\n",
            "Thought: To provide a comprehensive definition of machine learning, it would be beneficial to consult recent and reliable sources. I will use the document_search tool for this purpose.\n",
            "Action: document_search\n",
            "Action Input: \"What is machine learning?\"\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\185713141.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = qdrant_client.search(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mMachine Learning is an integral subfield of computer science, primarily focused on designing and implementing algorithms that can solve practical problems effectively by gathering a dataset and algorithmically constructing statistical models based on it. These solutions are useful as they do not rely explicitly programmed methods but rather derive mathematical formulas capable of producing desired outputs when applied to collections of inputs known as \"training data.\" While these systems might also perform well for most other unseen inputs, this largely depends if those come from the same or a similar statistical distribution as the training dataset. In essence, while machines don't learn in the human sense, they find patterns and infer rules that mimic learning by analogy with animal behavior rather than genuine understanding of data manipulation.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is machine learning?\n",
            "Thought: To provide a comprehensive definition of machine learning, it would be beneficial to consult recent and reliable sources. I will use the document_search tool for this purpose.\n",
            "Action: document_search\n",
            "Action Input: \"What is machine learning?\"\u001b[0m"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ASUS-3070\\AppData\\Local\\Temp\\ipykernel_10464\\185713141.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = qdrant_client.search(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mMachine Learning, often abbreviated as ML, is a subfield of computer science that focuses on building algorithms capable of discovering patterns and making predictions based on data without being explicitly programmed. These algorithms rely heavily on examples or datasets to learn from them through an iterative process known as training. The goal of machine learning methods typically involves constructing statistical models in order to automate analytical model building, thus facilitating problem-solving tasks such as classification and prediction which usually require insight into the system being studied. While machines don't \"learn\" like animals do, they perform a process by identifying mathematical relationships within data that can help them predict future outcomes or classify inputs based on past experiences—similar to how humans learn through practice and repetition of tasks. In essence, machine learning combines statistical techniques with algorithms designed to automatically improve performance when exposed to more data over time in an effort to reduce human intervention in automated processes.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Machine Learning is a subfield within computer science that develops algorithms capable of identifying patterns and making predictions based on datasets, with the aim of reducing reliance on explicit programming for problem-solving tasks such as classification and prediction without human intervention in automated processes. It employs statistical models to analyze data iteratively through training and seeks to improve performance by learning from more extensive data over time.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Machine Learning is a subfield within computer science that develops algorithms capable of identifying patterns and making predictions based on datasets, with the aim of reducing reliance on explicit programming for problem-solving tasks such as classification and prediction without human intervention in automated processes. It employs statistical models to analyze data iteratively through training and seeks to improve performance by learning from more extensive data over time.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is machine learning?\"\n",
        "response = agent.run(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
